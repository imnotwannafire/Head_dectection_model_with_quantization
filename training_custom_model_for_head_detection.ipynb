{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imnotwannafire/Head_dectection_model_with_quantization/blob/main/training_custom_model_for_head_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xat9q6veIeA",
        "outputId": "b51ea4d4-1e1f-4a7a-839e-8002d3aeaf73",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.159-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.159-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.159 ultralytics-thop-2.0.14\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.66-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.6.15)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.58.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n",
            "Downloading roboflow-1.1.66-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m133.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.1 roboflow-1.1.66\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG_rMoSiqFyc",
        "outputId": "3e2e9b13-941b-4e67-db6b-31a88d8f346c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYwSYsWVgnpI",
        "outputId": "2a4244af-9dc5-48fc-ae6a-a181f6b2aace",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/__init__.py\", line 918, in entrypoint\n",
            "    raise ValueError(f\"Invalid 'mode={mode}'. Valid modes are {list(MODES)}.\\n{CLI_HELP_MSG}\")\n",
            "ValueError: Invalid 'mode=<module 'ultralytics.utils.checks' from '/usr/local/lib/python3.11/dist-packages/ultralytics/utils/checks.py'>'. Valid modes are ['export', 'predict', 'track', 'train', 'benchmark', 'val'].\n",
            "\n",
            "    Arguments received: ['yolo', 'mode=checks']. Ultralytics 'yolo' commands use the following syntax:\n",
            "\n",
            "        yolo TASK MODE ARGS\n",
            "\n",
            "        Where   TASK (optional) is one of ['segment', 'detect', 'pose', 'obb', 'classify']\n",
            "                MODE (required) is one of ['export', 'predict', 'track', 'train', 'benchmark', 'val']\n",
            "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
            "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
            "\n",
            "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
            "        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n",
            "\n",
            "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
            "        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
            "\n",
            "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
            "        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n",
            "\n",
            "    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
            "        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n",
            "\n",
            "    5. Ultralytics solutions usage\n",
            "        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n",
            "\n",
            "    6. Run special commands:\n",
            "        yolo help\n",
            "        yolo checks\n",
            "        yolo version\n",
            "        yolo settings\n",
            "        yolo copy-cfg\n",
            "        yolo cfg\n",
            "        yolo solutions help\n",
            "\n",
            "    Docs: https://docs.ultralytics.com\n",
            "    Solutions: https://docs.ultralytics.com/solutions/\n",
            "    Community: https://community.ultralytics.com\n",
            "    GitHub: https://github.com/ultralytics/ultralytics\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "from IPython import display\n",
        "display.clear_output()\n",
        "!yolo mode=checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeHyLW8UhRWV",
        "outputId": "687e8c05-4846-46ff-c338-f1c0ab2fe052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Device: cuda\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Mount Drive và cài đặt\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# Kiểm tra GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/grove_ai_qat_training_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRKDiL9eq2la",
        "outputId": "8410eb01-f619-45d7-e6aa-da034cec9047"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/grove_ai_qat_training_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as7SP7WWhah_",
        "outputId": "941ed10c-593b-4f7f-9bb6-61128c05944e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in head_detection_on_bus-5 to yolov8:: 100%|██████████| 494397/494397 [00:37<00:00, 13309.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to head_detection_on_bus-5 in yolov8:: 100%|██████████| 17742/17742 [02:13<00:00, 132.61it/s]\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"xEK6F5JlUTrbdECVPjxE\")\n",
        "project = rf.workspace(\"grovevision\").project(\"head_detection_on_bus\")\n",
        "version = project.version(5)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8glq9Lsph2Uu",
        "outputId": "ba373540-e0f2-4286-ebaa-ac9343bb551b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/grove_ai_qat_training_2\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/grove_ai_qat_training_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnKgguANhZfq",
        "outputId": "fc22f9e3-f1b7-4489-dd11-ad797ada398f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GPU: Tesla T4\n",
            "✅ GPU Memory: 14.7 GB\n",
            "📁 Workspace: /content/drive/MyDrive/grove_ai_qat_training_2\n",
            "📊 Dataset: /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/data.yaml\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import yaml\n",
        "import time\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "\n",
        "# Clear GPU cache và setup\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f\"✅ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"✅ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "# ===== CONFIGURATION =====\n",
        "DATA_YAML_PATH = '/content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/data.yaml'\n",
        "WORKSPACE = '/content/drive/MyDrive/grove_ai_qat_training_2'\n",
        "os.makedirs(WORKSPACE, exist_ok=True)\n",
        "\n",
        "print(f\"📁 Workspace: {WORKSPACE}\")\n",
        "print(f\"📊 Dataset: {DATA_YAML_PATH}\")\n",
        "\n",
        "# Verify dataset exists\n",
        "if not os.path.exists(DATA_YAML_PATH):\n",
        "    raise FileNotFoundError(f\"Dataset not found: {DATA_YAML_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee9RWtD9iC2W",
        "outputId": "5502599a-fa71-465d-c71f-e0f2af19d9b9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 STAGE 1: HIGH RESOLUTION TRAINING (640x640)\n",
            "============================================================\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 205MB/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📋 Stage 1 Configuration:\n",
            "   imgsz: 640\n",
            "   epochs: 60\n",
            "   batch: 16\n",
            "   name: stage1_640_progressive\n",
            "   patience: 25\n",
            "   optimizer: AdamW\n",
            "   lr0: 0.01\n",
            "   device: 0\n",
            "   augment: True\n",
            "   save_period: 10\n",
            "   amp: True\n",
            "   workers: 8\n",
            "   cache: True\n",
            "   cos_lr: True\n",
            "   warmup_epochs: 3\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage1_640_progressive, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=25, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/grove_ai_qat_training_2, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 103MB/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 217MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.9±0.3 ms, read: 23.2±8.1 MB/s, size: 55.6 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/train/labels... 8331 images, 1 backgrounds, 0 corrupt: 100%|██████████| 8331/8331 [02:22<00:00, 58.55it/s] \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/train/labels.cache\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (5.7GB RAM): 100%|██████████| 8331/8331 [00:42<00:00, 195.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 6.6±1.1 MB/s, size: 43.4 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/valid/labels... 479 images, 0 backgrounds, 0 corrupt: 100%|██████████| 479/479 [00:05<00:00, 83.70it/s] \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/valid/labels.cache\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB RAM): 100%|██████████| 479/479 [00:02<00:00, 213.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/60       2.1G      1.614       1.59      1.488         61        640: 100%|██████████| 521/521 [02:36<00:00,  3.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.78it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        479        889      0.744      0.529      0.615        0.3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/60      2.33G      1.559      1.376       1.47         40        640: 100%|██████████| 521/521 [02:27<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.92it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        479        889      0.711      0.566      0.636      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/60      2.34G      1.499      1.231      1.428         37        640: 100%|██████████| 521/521 [02:24<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        479        889      0.753      0.663      0.745      0.438\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/60      2.36G      1.428      1.114      1.385         35        640: 100%|██████████| 521/521 [02:23<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.49it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        479        889      0.745      0.583       0.68      0.371\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/60      2.38G      1.384       1.05      1.349         46        640: 100%|██████████| 521/521 [02:23<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        479        889      0.867      0.826       0.91      0.587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/60       2.4G      1.344     0.9815      1.323         39        640: 100%|██████████| 521/521 [02:21<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.68it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        479        889      0.861       0.76      0.848      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/60      2.41G      1.321     0.9369      1.305         36        640: 100%|██████████| 521/521 [02:19<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  3.82it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        479        889      0.914      0.852      0.938      0.621\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/60      2.43G      1.297     0.9012      1.288         29        640: 100%|██████████| 521/521 [02:25<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        479        889      0.917       0.82      0.919      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/60      2.45G      1.271     0.8654      1.269         44        640: 100%|██████████| 521/521 [02:25<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.07it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        479        889      0.884      0.875      0.933      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/60      2.46G      1.249     0.8445      1.258         45        640: 100%|██████████| 521/521 [02:28<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.06it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        479        889      0.891       0.87      0.931      0.633\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/60      2.48G       1.23     0.8178      1.242         34        640: 100%|██████████| 521/521 [02:27<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.909       0.87      0.944      0.604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/60       2.5G      1.224     0.7933      1.239         43        640: 100%|██████████| 521/521 [02:29<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.927      0.881      0.948       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/60      2.52G      1.199     0.7759      1.219         42        640: 100%|██████████| 521/521 [02:26<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.928      0.881      0.949      0.652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/60      2.53G      1.193     0.7631      1.217         45        640: 100%|██████████| 521/521 [02:22<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.933      0.864      0.947      0.639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/60      2.55G      1.176     0.7457      1.209         51        640: 100%|██████████| 521/521 [02:20<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.883      0.881      0.939      0.636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/60      2.57G      1.167     0.7358      1.206         32        640: 100%|██████████| 521/521 [02:19<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.922       0.89      0.951      0.638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/60      2.58G      1.149     0.7206      1.192         49        640: 100%|██████████| 521/521 [02:20<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.899      0.927      0.949      0.656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/60       2.6G      1.139     0.6996      1.185         44        640: 100%|██████████| 521/521 [02:19<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.915       0.89      0.951      0.669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/60      2.62G      1.124     0.6895      1.171         48        640: 100%|██████████| 521/521 [02:19<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.923      0.915      0.963      0.679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/60      2.63G      1.111     0.6757      1.167         37        640: 100%|██████████| 521/521 [02:20<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.932      0.894      0.957      0.653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/60      2.65G      1.105     0.6633      1.164         43        640: 100%|██████████| 521/521 [02:19<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.92      0.914       0.96      0.687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/60      2.67G        1.1     0.6579      1.158         48        640: 100%|██████████| 521/521 [02:18<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.918       0.91      0.959      0.679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/60      2.69G      1.078     0.6455      1.147         36        640: 100%|██████████| 521/521 [02:19<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.942       0.91      0.957      0.677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/60       2.7G      1.071     0.6315      1.138         34        640: 100%|██████████| 521/521 [02:19<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.915      0.904      0.956      0.685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/60      2.72G      1.061     0.6192      1.131         37        640: 100%|██████████| 521/521 [02:17<00:00,  3.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.913      0.931       0.96      0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/60      2.74G      1.052     0.6177       1.13         36        640: 100%|██████████| 521/521 [02:19<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.944      0.918      0.962      0.692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/60      2.75G      1.043     0.6061      1.118         50        640: 100%|██████████| 521/521 [02:18<00:00,  3.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.924      0.928      0.962      0.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/60      2.77G      1.029      0.597      1.111         43        640: 100%|██████████| 521/521 [02:19<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.932      0.926      0.965      0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/60      2.79G      1.027     0.5886      1.113         35        640: 100%|██████████| 521/521 [02:19<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.955       0.91      0.967      0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/60       2.8G      1.001     0.5721      1.097         62        640: 100%|██████████| 521/521 [02:19<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.939      0.925      0.971      0.694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/60      2.82G     0.9975     0.5642      1.093         43        640: 100%|██████████| 521/521 [02:20<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.933      0.942      0.967      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/60      2.84G     0.9908     0.5617      1.086         64        640: 100%|██████████| 521/521 [02:19<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.95      0.914      0.965        0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/60      2.86G     0.9933     0.5586      1.093         36        640: 100%|██████████| 521/521 [02:20<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.923      0.947       0.97      0.698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/60      2.87G     0.9806     0.5515      1.083         47        640: 100%|██████████| 521/521 [02:19<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.936       0.94      0.974      0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/60      2.89G     0.9698     0.5403      1.072         60        640: 100%|██████████| 521/521 [02:21<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.947      0.927      0.971      0.707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/60      2.91G     0.9622     0.5313      1.069         45        640: 100%|██████████| 521/521 [02:22<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.954      0.924      0.974       0.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/60      2.93G     0.9542     0.5261      1.066         56        640: 100%|██████████| 521/521 [02:22<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.936      0.939      0.972       0.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/60      2.94G      0.941     0.5232      1.059         38        640: 100%|██████████| 521/521 [02:21<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.947      0.936      0.974      0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/60      2.96G      0.941     0.5156      1.057         44        640: 100%|██████████| 521/521 [02:19<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.943      0.938      0.971      0.708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/60      2.98G     0.9306     0.5078      1.052         31        640: 100%|██████████| 521/521 [02:21<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.948      0.936       0.97      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/60      2.99G     0.9255     0.5012      1.051         41        640: 100%|██████████| 521/521 [02:20<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.955      0.931       0.97      0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/60      3.01G     0.9167     0.4964      1.047         32        640: 100%|██████████| 521/521 [02:20<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.939      0.945      0.971      0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/60      3.03G     0.9055     0.4868       1.04         54        640: 100%|██████████| 521/521 [02:21<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.948      0.934      0.972      0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/60      3.04G     0.9057     0.4878      1.042         40        640: 100%|██████████| 521/521 [02:19<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.94      0.947      0.972      0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/60      3.06G     0.8924     0.4777      1.032         43        640: 100%|██████████| 521/521 [02:24<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.941      0.945      0.972      0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/60      3.08G     0.8885     0.4732      1.029         33        640: 100%|██████████| 521/521 [02:24<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.94       0.95      0.971      0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/60       3.1G     0.8828     0.4719      1.029         35        640: 100%|██████████| 521/521 [02:23<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.954      0.943      0.971      0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/60      3.11G     0.8768      0.468      1.028         33        640: 100%|██████████| 521/521 [02:23<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.948      0.947      0.975      0.709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/60      3.13G      0.873     0.4649      1.025         26        640: 100%|██████████| 521/521 [02:21<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.948      0.938      0.974      0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/60      3.14G     0.8623     0.4602      1.018         27        640: 100%|██████████| 521/521 [02:22<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.955      0.936      0.973      0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      51/60      3.16G     0.8356     0.4057       1.02         33        640: 100%|██████████| 521/521 [02:20<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.947      0.939      0.971       0.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      52/60      3.18G      0.805     0.3846      1.003         23        640: 100%|██████████| 521/521 [02:18<00:00,  3.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.948      0.931      0.974      0.721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      53/60       3.2G     0.7898     0.3763      0.996         24        640: 100%|██████████| 521/521 [02:13<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.95      0.935      0.972       0.72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      54/60      3.21G     0.7896     0.3731     0.9982         18        640: 100%|██████████| 521/521 [02:15<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.939      0.945      0.974      0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      55/60      3.23G     0.7845       0.37     0.9928         22        640: 100%|██████████| 521/521 [02:14<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.94      0.944      0.973      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      56/60      3.25G     0.7819     0.3702     0.9907         18        640: 100%|██████████| 521/521 [02:14<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.947      0.943      0.973      0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      57/60      3.27G     0.7774     0.3674     0.9891         28        640: 100%|██████████| 521/521 [02:16<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.95      0.935      0.973      0.721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      58/60      3.28G      0.775     0.3669     0.9891         18        640: 100%|██████████| 521/521 [02:14<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.949       0.94      0.973      0.721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      59/60       3.3G     0.7793     0.3672     0.9923         22        640: 100%|██████████| 521/521 [02:13<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:02<00:00,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.948      0.942      0.973      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      60/60      3.32G       0.77     0.3666     0.9883         25        640: 100%|██████████| 521/521 [02:16<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:03<00:00,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.945      0.942      0.973      0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "60 epochs completed in 2.410 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive/weights/best.pt...\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.938      0.935      0.973      0.719\n",
            "Speed: 0.1ms preprocess, 5.0ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "print(\"🚀 STAGE 1: HIGH RESOLUTION TRAINING (640x640)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Initialize YOLOv8n model\n",
        "model_stage1 = YOLO('yolov8n.pt')\n",
        "\n",
        "# Stage 1 Configuration\n",
        "stage1_config = {\n",
        "    'data': DATA_YAML_PATH,\n",
        "    'imgsz': 640,                     # High resolution cho feature learning\n",
        "    'epochs': 60,\n",
        "    'batch': 16,                      # Optimized cho 15GB GPU\n",
        "    'name': 'stage1_640_progressive',\n",
        "    'project': WORKSPACE,\n",
        "    'patience': 25,\n",
        "    'optimizer': 'AdamW',\n",
        "    'lr0': 0.01,                      # Standard learning rate\n",
        "    'device': 0,\n",
        "    'augment': True,\n",
        "    'save_period': 10,\n",
        "    'amp': True,                      # Mixed precision\n",
        "    'workers': 8,\n",
        "    'cache': True,\n",
        "    'cos_lr': True,\n",
        "    'warmup_epochs': 3\n",
        "}\n",
        "\n",
        "print(\"📋 Stage 1 Configuration:\")\n",
        "for key, value in stage1_config.items():\n",
        "    if key not in ['data', 'project']:\n",
        "        print(f\"   {key}: {value}\")\n",
        "\n",
        "# Execute Stage 1 training\n",
        "start_time = time.time()\n",
        "results_stage1 = model_stage1.train(**stage1_config)\n",
        "stage1_duration = (time.time() - start_time) / 3600\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkTj4pfmJFx-",
        "outputId": "f0decff5-9642-4134-b9a3-fdb775ac9a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Model: /content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive/weights/best.pt\n",
            "   Size: 5.95MB\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.8±0.7 ms, read: 8.0±2.9 MB/s, size: 51.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/valid/labels.cache... 479 images, 0 backgrounds, 0 corrupt: 100%|██████████| 479/479 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:07<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.947      0.943      0.973      0.722\n",
            "Speed: 0.4ms preprocess, 4.3ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "   mAP@0.5: 0.9729\n"
          ]
        }
      ],
      "source": [
        "# Get Stage 1 model path\n",
        "stage1_model_path = '/content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive/weights/best.pt'\n",
        "model_stage1 = YOLO('/content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive/weights/best.pt')\n",
        "if os.path.exists(stage1_model_path):\n",
        "    stage1_size = os.path.getsize(stage1_model_path) / (1024**2)\n",
        "    # print(f\"✅ Stage 1 completed in {stage1_duration:.2f}h\")\n",
        "    print(f\"   Model: {stage1_model_path}\")\n",
        "    print(f\"   Size: {stage1_size:.2f}MB\")\n",
        "\n",
        "    # Backup to workspace\n",
        "    shutil.copy2(stage1_model_path, os.path.join(WORKSPACE, 'stage1_best.pt'))\n",
        "\n",
        "    # Quick validation\n",
        "    val_results_s1 = model_stage1.val(data=DATA_YAML_PATH, imgsz=640, verbose=False)\n",
        "    print(f\"   mAP@0.5: {val_results_s1.box.map50:.4f}\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"Stage 1 training failed!\")\n",
        "# stage1_model_path = '/content/drive/MyDrive/grove_ai_qat_training/stage1_640_progressive/weights/best.pt'\n",
        "# print(stage1_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2V3VX3ZiKnu",
        "outputId": "ba5aaa80-471c-43ae-d542-d12a262a019c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 STAGE 2: FINE-TUNING (192x192)\n",
            "==================================================\n",
            "✅ Loaded Stage 1 model for fine-tuning\n",
            "📋 Stage 2 Configuration:\n",
            "   Target resolution: 192x192\n",
            "   Learning rate: 0.001 (fine-tuning)\n",
            "   Batch size: 32\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=192, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.0001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/grove_ai_qat_training_2/stage1_640_progressive/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=stage2_192_finetune, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/grove_ai_qat_training_2, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/grove_ai_qat_training_2/stage2_192_finetune, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 8.0±4.5 MB/s, size: 55.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/train/labels.cache... 8331 images, 1 backgrounds, 0 corrupt: 100%|██████████| 8331/8331 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.8±0.4 ms, read: 23.0±9.4 MB/s, size: 47.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/valid/labels.cache... 479 images, 0 backgrounds, 0 corrupt: 100%|██████████| 479/479 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/MyDrive/grove_ai_qat_training_2/stage2_192_finetune/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 192 train, 192 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/grove_ai_qat_training_2/stage2_192_finetune\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/40     0.863G      1.926      1.374      1.214         37        192: 100%|██████████| 261/261 [01:16<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.741      0.477      0.558      0.285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/40     0.863G      1.798       1.17      1.135         39        192: 100%|██████████| 261/261 [01:15<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.769      0.567      0.654       0.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/40     0.863G      1.725      1.102      1.104         60        192: 100%|██████████| 261/261 [01:12<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.828      0.602      0.704      0.373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/40     0.863G       1.66      1.041      1.086         52        192: 100%|██████████| 261/261 [01:11<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.852      0.634      0.736      0.407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/40     0.863G       1.62     0.9998       1.07         50        192: 100%|██████████| 261/261 [01:09<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.845      0.651       0.76       0.43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/40     0.863G      1.597     0.9757      1.058         45        192: 100%|██████████| 261/261 [01:10<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.84      0.676      0.781      0.424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/40     0.863G      1.567     0.9482       1.05         44        192: 100%|██████████| 261/261 [01:11<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.87      0.686      0.808      0.461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/40     0.863G      1.554     0.9349      1.045         61        192: 100%|██████████| 261/261 [01:11<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.856       0.69      0.799      0.447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/40     0.863G      1.534     0.9181      1.038         35        192: 100%|██████████| 261/261 [01:09<00:00,  3.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.884      0.694      0.817       0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/40     0.863G      1.528     0.9102      1.037         44        192: 100%|██████████| 261/261 [01:10<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.87      0.706      0.822      0.467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/40     0.863G      1.513     0.8966      1.029         25        192: 100%|██████████| 261/261 [01:10<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.879       0.72      0.834      0.478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/40     0.863G        1.5     0.8863       1.03         36        192: 100%|██████████| 261/261 [01:12<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.884      0.717      0.834      0.482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/40     0.863G      1.497     0.8814      1.022         54        192: 100%|██████████| 261/261 [01:11<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.876      0.713       0.83       0.49\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/40     0.863G      1.486     0.8731       1.02         39        192: 100%|██████████| 261/261 [01:11<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.899      0.721      0.844      0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/40     0.863G      1.482     0.8656      1.018         37        192: 100%|██████████| 261/261 [01:11<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.892      0.739       0.85      0.491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/40     0.863G      1.464     0.8565      1.019         42        192: 100%|██████████| 261/261 [01:11<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.867      0.732      0.837      0.481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/40     0.863G      1.467     0.8471      1.017         31        192: 100%|██████████| 261/261 [01:10<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.886      0.727      0.845      0.487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/40     0.863G      1.464     0.8508      1.013         26        192: 100%|██████████| 261/261 [01:10<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.905      0.719       0.85      0.493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/40     0.863G      1.453     0.8457      1.011         31        192: 100%|██████████| 261/261 [01:10<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.896      0.746      0.859        0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/40     0.863G       1.46      0.842      1.011         43        192: 100%|██████████| 261/261 [01:10<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.903      0.732      0.853      0.497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/40     0.863G      1.448     0.8307      1.007         42        192: 100%|██████████| 261/261 [01:09<00:00,  3.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889        0.9      0.739      0.863      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/40     0.863G      1.448     0.8326      1.003         67        192: 100%|██████████| 261/261 [01:11<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.905      0.732      0.864      0.508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/40     0.863G      1.432      0.823      1.006         32        192: 100%|██████████| 261/261 [01:10<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.885      0.744      0.865      0.504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/40     0.863G      1.438     0.8262          1         51        192: 100%|██████████| 261/261 [01:09<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.897      0.748      0.871      0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/40     0.863G      1.438     0.8225      1.003         41        192: 100%|██████████| 261/261 [01:10<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.878      0.757      0.866      0.501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/40     0.863G      1.434     0.8172      1.003         41        192: 100%|██████████| 261/261 [01:10<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.853      0.782      0.872      0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/40     0.863G      1.427     0.8145          1         30        192: 100%|██████████| 261/261 [01:09<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.873      0.776      0.877      0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/40     0.863G      1.424     0.8133     0.9983         55        192: 100%|██████████| 261/261 [01:12<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.876      0.782      0.878      0.521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/40     0.863G      1.413     0.8075     0.9971         52        192: 100%|██████████| 261/261 [01:12<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.864      0.779      0.872      0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/40     0.863G      1.427     0.8119     0.9985         42        192: 100%|██████████| 261/261 [01:10<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.868      0.785      0.878      0.518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/40     0.863G      1.299     0.6992     0.9819         22        192: 100%|██████████| 261/261 [01:11<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.857      0.792      0.865       0.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/40     0.863G      1.279     0.6746     0.9731         18        192: 100%|██████████| 261/261 [01:12<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.873      0.787      0.872      0.518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/40     0.863G      1.264     0.6634     0.9708         18        192: 100%|██████████| 261/261 [01:10<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.863      0.783      0.872      0.518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/40     0.863G      1.257     0.6582     0.9696         28        192: 100%|██████████| 261/261 [01:10<00:00,  3.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.863      0.781      0.871      0.517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/40     0.863G      1.256     0.6594      0.967         30        192: 100%|██████████| 261/261 [01:10<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.861      0.792      0.873      0.521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/40     0.863G      1.256     0.6542      0.968         16        192: 100%|██████████| 261/261 [01:11<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.86      0.794      0.873      0.522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/40     0.863G      1.251     0.6492     0.9666         17        192: 100%|██████████| 261/261 [01:11<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.858      0.793      0.872      0.521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/40     0.863G      1.254     0.6579     0.9667         21        192: 100%|██████████| 261/261 [01:10<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.861      0.791      0.873       0.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/40     0.863G      1.248     0.6518     0.9642         14        192: 100%|██████████| 261/261 [01:11<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.867      0.784      0.873      0.521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/40     0.863G      1.261     0.6585     0.9684         28        192: 100%|██████████| 261/261 [01:11<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:03<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889       0.86      0.785      0.873       0.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "40 epochs completed in 0.840 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/grove_ai_qat_training_2/stage2_192_finetune/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/grove_ai_qat_training_2/stage2_192_finetune/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/grove_ai_qat_training_2/stage2_192_finetune/weights/best.pt...\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:05<00:00,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.862      0.713      0.839      0.504\n",
            "Speed: 0.0ms preprocess, 2.8ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/grove_ai_qat_training_2/stage2_192_finetune\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n🎯 STAGE 2: FINE-TUNING (192x192)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Load Stage 1 model\n",
        "model_stage2 = YOLO(stage1_model_path)\n",
        "print(f\"✅ Loaded Stage 1 model for fine-tuning\")\n",
        "\n",
        "# Stage 2 Configuration\n",
        "stage2_config = {\n",
        "    'data': DATA_YAML_PATH,           # 🔥 SAME dataset\n",
        "    'imgsz': 192,                     # Target resolution cho Grove AI\n",
        "    'epochs': 40,\n",
        "    'batch': 32,                      # Higher batch với lower resolution\n",
        "    'name': 'stage2_192_finetune',\n",
        "    'project': WORKSPACE,\n",
        "    'patience': 20,\n",
        "    'optimizer': 'AdamW',\n",
        "    'lr0': 0.001,                     # 10x lower than Stage 1\n",
        "    'lrf': 0.0001,\n",
        "    'warmup_epochs': 5,\n",
        "    'warmup_momentum': 0.8,\n",
        "    'cos_lr': True,\n",
        "    'augment': True,\n",
        "    'save_period': 5,\n",
        "    'amp': True,\n",
        "    'workers': 8\n",
        "}\n",
        "\n",
        "print(\"📋 Stage 2 Configuration:\")\n",
        "print(f\"   Target resolution: {stage2_config['imgsz']}x{stage2_config['imgsz']}\")\n",
        "print(f\"   Learning rate: {stage2_config['lr0']} (fine-tuning)\")\n",
        "print(f\"   Batch size: {stage2_config['batch']}\")\n",
        "\n",
        "# Execute Stage 2 training\n",
        "start_time = time.time()\n",
        "results_stage2 = model_stage2.train(**stage2_config)\n",
        "stage2_duration = (time.time() - start_time) / 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GJHPkqb9JeSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf39788-c025-44df-db8c-dc7efc4c755e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Model: /content/drive/MyDrive/grove_ai_qat_training_2/stage2_192_finetune/weights/best.pt\n",
            "   Size: 5.91MB\n"
          ]
        }
      ],
      "source": [
        "# Get Stage 2 model path\n",
        "stage2_model_path = os.path.join('/content/drive/MyDrive/grove_ai_qat_training_2/stage2_192_finetune', 'weights', 'best.pt')\n",
        "\n",
        "if os.path.exists(stage2_model_path):\n",
        "    stage2_size = os.path.getsize(stage2_model_path) / (1024**2)\n",
        "    # print(f\"✅ Stage 2 completed in {stage2_duration:.1f}min\")\n",
        "    print(f\"   Model: {stage2_model_path}\")\n",
        "    print(f\"   Size: {stage2_size:.2f}MB\")\n",
        "\n",
        "    # Backup to workspace\n",
        "    shutil.copy2(stage2_model_path, os.path.join(WORKSPACE, 'stage2_best.pt'))\n",
        "\n",
        "    # Validation\n",
        "#     val_results_s2 = model_stage2.val(data=DATA_YAML_PATH, imgsz=192, verbose=False)\n",
        "#     print(f\"   mAP@0.5: {val_results_s2.box.map50:.4f}\")\n",
        "# else:\n",
        "#     raise FileNotFoundError(\"Stage 2 training failed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oSWb3g8MiNRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "514ff661-96fb-44bd-9ff4-405d72d92091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💎 STAGE 3: QUANTIZATION-AWARE TRAINING (QAT)\n",
            "=======================================================\n",
            "✅ Loaded Stage 2 model for QAT\n",
            "📋 QAT Configuration:\n",
            "   Learning rate: 5e-05 (ultra-low)\n",
            "   Augmentation: Minimal (stability focus)\n",
            "   Mixed precision: Disabled\n",
            "   Target: INT8 quantization ready\n",
            "🔄 Starting QAT training...\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=48, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/data.yaml, degrees=1.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=25, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.005, hsv_s=0.3, hsv_v=0.2, imgsz=192, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=5e-05, lrf=5e-06, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/grove_ai_qat_training_2/stage2_192_finetune/weights/best.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=qat_grove_ai_optimized, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=12, perspective=5e-06, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/grove_ai_qat_training_2, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized, save_frames=False, save_json=False, save_period=3, save_txt=False, scale=0.01, seed=0, shear=0.2, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.01, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=2, warmup_momentum=0.8, weight_decay=0.0005, workers=6, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 17.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 1.2±1.8 ms, read: 21.9±13.7 MB/s, size: 55.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/train/labels... 8331 images, 1 backgrounds, 0 corrupt: 100%|██████████| 8331/8331 [02:22<00:00, 58.43it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/train/labels.cache\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.5GB RAM): 100%|██████████| 8331/8331 [00:39<00:00, 212.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.7±0.3 ms, read: 18.5±12.3 MB/s, size: 43.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/valid/labels... 479 images, 0 backgrounds, 0 corrupt: 100%|██████████| 479/479 [00:05<00:00, 93.08it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/valid/labels.cache\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM): 100%|██████████| 479/479 [00:02<00:00, 218.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=5e-05, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.000375), 63 bias(decay=0.0)\n",
            "Image sizes 192 train, 192 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/25      1.03G      1.286     0.6959     0.9686         93        192: 100%|██████████| 174/174 [00:32<00:00,  5.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:03<00:00,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.866      0.736      0.827      0.447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/25      1.34G       1.24     0.6464     0.9523         56        192: 100%|██████████| 174/174 [00:31<00:00,  5.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.904      0.763      0.873      0.527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/25      1.36G      1.209     0.6254     0.9447         54        192: 100%|██████████| 174/174 [00:29<00:00,  5.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.867      0.796      0.874      0.531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/25      1.38G      1.203     0.6204     0.9412         54        192: 100%|██████████| 174/174 [00:29<00:00,  5.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.869      0.801      0.878      0.533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/25      1.39G      1.202     0.6151     0.9415         61        192: 100%|██████████| 174/174 [00:30<00:00,  5.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.878      0.794      0.876      0.533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/25      1.41G      1.197      0.614     0.9408         67        192: 100%|██████████| 174/174 [00:29<00:00,  5.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.881      0.791      0.877      0.535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/25      1.42G      1.199      0.614     0.9406         46        192: 100%|██████████| 174/174 [00:29<00:00,  5.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.879      0.794      0.877      0.534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/25      1.44G      1.189     0.6102     0.9389         52        192: 100%|██████████| 174/174 [00:29<00:00,  5.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.881      0.793      0.878      0.535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/25      1.46G      1.192     0.6095     0.9387         65        192: 100%|██████████| 174/174 [00:29<00:00,  5.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.884      0.795      0.879      0.535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/25      1.48G      1.189     0.6078     0.9385         59        192: 100%|██████████| 174/174 [00:30<00:00,  5.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.884      0.794      0.878      0.535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/25      1.49G      1.186     0.6067     0.9368         50        192: 100%|██████████| 174/174 [00:29<00:00,  5.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.881      0.795      0.878      0.537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/25      1.51G      1.189     0.6056     0.9375         53        192: 100%|██████████| 174/174 [00:29<00:00,  5.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.887      0.793       0.88      0.537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/25      1.53G      1.187     0.6062     0.9352         57        192: 100%|██████████| 174/174 [00:29<00:00,  5.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.892      0.791      0.878      0.537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/25      1.55G      1.181     0.6036     0.9352         74        192: 100%|██████████| 174/174 [00:30<00:00,  5.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.884      0.798      0.878      0.536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/25      1.56G      1.186     0.6056     0.9363         46        192: 100%|██████████| 174/174 [00:30<00:00,  5.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.886      0.794      0.878      0.536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/25      1.58G       1.18     0.6034     0.9361         58        192: 100%|██████████| 174/174 [00:32<00:00,  5.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.884      0.795      0.879      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/25       1.6G      1.179     0.6014     0.9367         55        192: 100%|██████████| 174/174 [00:32<00:00,  5.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.886      0.798      0.878      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/25      1.61G      1.182     0.6009     0.9363         64        192: 100%|██████████| 174/174 [00:30<00:00,  5.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.887      0.793      0.879      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/25      1.63G       1.18     0.6036     0.9353         68        192: 100%|██████████| 174/174 [00:30<00:00,  5.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.887      0.798      0.878      0.539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/25      1.65G      1.181     0.5997     0.9365         57        192: 100%|██████████| 174/174 [00:31<00:00,  5.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.887      0.798      0.879      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/25      1.66G       1.18     0.6007     0.9348         56        192: 100%|██████████| 174/174 [00:30<00:00,  5.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.886      0.796      0.879      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/25      1.68G      1.177        0.6     0.9351         48        192: 100%|██████████| 174/174 [00:30<00:00,  5.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.889      0.793      0.879      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/25       1.7G      1.178        0.6     0.9335         53        192: 100%|██████████| 174/174 [00:30<00:00,  5.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.883      0.795      0.879      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/25      1.71G      1.178     0.5995     0.9342         59        192: 100%|██████████| 174/174 [00:30<00:00,  5.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.883      0.799      0.879      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/25      1.73G      1.177     0.5991     0.9343         49        192: 100%|██████████| 174/174 [00:30<00:00,  5.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.884      0.795      0.879      0.539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "25 epochs completed in 0.226 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights/best.pt...\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.885      0.796      0.879      0.538\n",
            "Speed: 0.0ms preprocess, 0.5ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n💎 STAGE 3: QUANTIZATION-AWARE TRAINING (QAT)\")\n",
        "print(\"=\"*55)\n",
        "\n",
        "# Load Stage 2 model\n",
        "model_qat = YOLO(stage2_model_path)\n",
        "print(f\"✅ Loaded Stage 2 model for QAT\")\n",
        "\n",
        "# QAT Configuration - CRITICAL PARAMETERS\n",
        "qat_config = {\n",
        "    'data': DATA_YAML_PATH,\n",
        "    'imgsz': 192,                     # Grove AI Vision target\n",
        "    'epochs': 25,                     # QAT needs fewer epochs\n",
        "    'batch': 48,                      # Slightly reduced for stability\n",
        "    'name': 'qat_grove_ai_optimized',\n",
        "    'project': WORKSPACE,\n",
        "    'patience': 12,\n",
        "    'optimizer': 'AdamW',\n",
        "\n",
        "    # 🔥 CRITICAL: Ultra-low learning rates cho QAT\n",
        "    'lr0': 0.00005,                   # 200x lower than Stage 1\n",
        "    'lrf': 0.000005,                  # Extremely low final LR\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'warmup_epochs': 2,\n",
        "    'warmup_momentum': 0.8,\n",
        "\n",
        "    # Minimal augmentation cho QAT stability\n",
        "    'degrees': 1.0,                   # Minimal rotation\n",
        "    'translate': 0.01,                # Minimal translation\n",
        "    'scale': 0.01,                    # Minimal scaling\n",
        "    'shear': 0.2,                     # Minimal shear\n",
        "    'perspective': 0.000005,          # Almost no perspective\n",
        "    'fliplr': 0.5,                    # Keep horizontal flip\n",
        "\n",
        "    # Disable complex augmentations\n",
        "    'mixup': 0.0,\n",
        "    'mosaic': 0.0,\n",
        "    'copy_paste': 0.0,\n",
        "    'hsv_h': 0.005,\n",
        "    'hsv_s': 0.3,\n",
        "    'hsv_v': 0.2,\n",
        "\n",
        "    # QAT-specific settings\n",
        "    'cos_lr': True,\n",
        "    'amp': False,                     # 🔥 CRITICAL: No mixed precision\n",
        "    'save_period': 3,\n",
        "    'val': True,\n",
        "    'plots': True,\n",
        "    'workers': 6,\n",
        "    'cache': True\n",
        "}\n",
        "\n",
        "print(\"📋 QAT Configuration:\")\n",
        "print(f\"   Learning rate: {qat_config['lr0']} (ultra-low)\")\n",
        "print(f\"   Augmentation: Minimal (stability focus)\")\n",
        "print(f\"   Mixed precision: Disabled\")\n",
        "print(f\"   Target: INT8 quantization ready\")\n",
        "\n",
        "# Clear GPU cache\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Execute QAT training\n",
        "print(\"🔄 Starting QAT training...\")\n",
        "start_time = time.time()\n",
        "results_qat = model_qat.train(**qat_config)\n",
        "qat_duration = (time.time() - start_time) / 60\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get QAT model path\n",
        "qat_model_path = os.path.join(qat_config['project'],qat_config['name'], 'weights', 'best.pt')\n",
        "\n",
        "if os.path.exists(qat_model_path):\n",
        "    qat_size = os.path.getsize(qat_model_path) / (1024**2)\n",
        "    print(f\"✅ QAT completed in {qat_duration:.1f}min\")\n",
        "    print(f\"   Model: {qat_model_path}\")\n",
        "    print(f\"   Size: {qat_size:.2f}MB\")\n",
        "\n",
        "    # Backup to workspace\n",
        "    shutil.copy2(qat_model_path, os.path.join(WORKSPACE, 'qat_best.pt'))\n",
        "\n",
        "    # Validation\n",
        "    val_results_qat = model_qat.val(data=DATA_YAML_PATH, imgsz=192, verbose=False)\n",
        "    print(f\"   mAP@0.5: {val_results_qat.box.map50:.4f}\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"QAT training failed!\")"
      ],
      "metadata": {
        "id": "KyDd1Re-ntzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cd1123-bf9d-47f0-d259-9d5dd53c0dfa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ QAT completed in 17.2min\n",
            "   Model: /content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights/best.pt\n",
            "   Size: 5.91MB\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 28.7±7.9 MB/s, size: 51.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/valid/labels.cache... 479 images, 0 backgrounds, 0 corrupt: 100%|██████████| 479/479 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB RAM): 100%|██████████| 479/479 [00:02<00:00, 224.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:03<00:00,  2.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.884      0.794      0.879      0.539\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized2\u001b[0m\n",
            "   mAP@0.5: 0.8792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0Kar4871iP54"
      },
      "outputs": [],
      "source": [
        "def create_representative_dataset(data_yaml_path, num_samples=100):\n",
        "    \"\"\"Tạo representative dataset cho optimal TFLite calibration\"\"\"\n",
        "\n",
        "    print(\"📊 Creating representative dataset for TFLite calibration...\")\n",
        "\n",
        "    try:\n",
        "        # Load data config\n",
        "        parent_directory = os.path.dirname(data_yaml_path)\n",
        "\n",
        "\n",
        "        # Get validation images path\n",
        "        val_path = os.path.join(parent_directory, 'valid')\n",
        "        if not val_path:\n",
        "            val_path = os.path.join(parent_directory, 'train')\n",
        "\n",
        "        if not val_path:\n",
        "            print(\"❌ No image path found in data.yaml\")\n",
        "            return None\n",
        "\n",
        "        print(val_path)\n",
        "        # Find images\n",
        "        import glob\n",
        "        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
        "        image_files = []\n",
        "\n",
        "        for ext in image_extensions:\n",
        "            pattern = f\"{val_path}/images/{ext}\"\n",
        "            image_files.extend(glob.glob(pattern))\n",
        "            image_files.extend(glob.glob(pattern.upper()))\n",
        "\n",
        "        if not image_files:\n",
        "            print(f\"❌ No images found in {val_path}/images/\")\n",
        "            return None\n",
        "\n",
        "        # Sample representative images\n",
        "        np.random.seed(42)\n",
        "        np.random.shuffle(image_files)\n",
        "        selected_files = image_files[:min(num_samples, len(image_files))]\n",
        "\n",
        "        print(f\"✅ Representative dataset: {len(selected_files)} images\")\n",
        "\n",
        "        def representative_data_gen():\n",
        "            \"\"\"Generator cho TFLite calibration\"\"\"\n",
        "            for img_path in selected_files:\n",
        "                try:\n",
        "                    # Load image\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is None:\n",
        "                        continue\n",
        "\n",
        "                    # Letterbox resize to 192x192 (exact Grove AI preprocessing)\n",
        "                    h, w = img.shape[:2]\n",
        "                    r = min(192/h, 192/w)\n",
        "                    new_w, new_h = int(w * r), int(h * r)\n",
        "\n",
        "                    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "                    # Create canvas với gray padding (114)\n",
        "                    canvas = np.full((192, 192, 3), 114, dtype=np.uint8)\n",
        "                    y_offset = (192 - new_h) // 2\n",
        "                    x_offset = (192 - new_w) // 2\n",
        "                    canvas[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n",
        "\n",
        "                    # Normalize to [0,1] và add batch dimension\n",
        "                    processed = canvas.astype(np.float32) / 255.0\n",
        "                    processed = np.expand_dims(processed, axis=0)\n",
        "\n",
        "                    yield [processed]\n",
        "\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "        return representative_data_gen\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error creating representative dataset: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oUM4Fx2siT-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84851f5-fb7f-4724-b803-533f2a68aeba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📦 EXPORTING TO TFLITE (INT8 QUANTIZED)\n",
            "==================================================\n",
            "📊 Creating representative dataset for TFLite calibration...\n",
            "/content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/valid\n",
            "✅ Representative dataset: 100 images\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n📦 EXPORTING TO TFLITE (INT8 QUANTIZED)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Load QAT model\n",
        "model_export = YOLO(qat_model_path)\n",
        "\n",
        "# Create representative dataset\n",
        "rep_dataset_gen = create_representative_dataset(DATA_YAML_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if rep_dataset_gen is None:\n",
        "    print(\"⚠️  Exporting without representative dataset calibration...\")\n",
        "\n",
        "    # Basic export\n",
        "    tflite_path = model_export.export(\n",
        "        format='tflite',\n",
        "        imgsz=192,\n",
        "        int8=True,\n",
        "        optimize=True,\n",
        "        simplify=True,\n",
        "        dynamic=False,\n",
        "        batch=1\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\"🎯 Exporting với representative dataset calibration...\")\n",
        "\n",
        "    try:\n",
        "        # Export to SavedModel first\n",
        "        print(\"   Step 1: Exporting to SavedModel...\")\n",
        "        saved_model_path = model_export.export(\n",
        "            format='saved_model',\n",
        "            imgsz=192,\n",
        "            optimize=True,\n",
        "            simplify=True,\n",
        "            dynamic=False,\n",
        "            batch=1\n",
        "        )\n",
        "\n",
        "        # Manual TFLite conversion với calibration\n",
        "        print(\"   Step 2: Converting to TFLite với calibration...\")\n",
        "        import tensorflow as tf\n",
        "\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "        converter.inference_input_type = tf.uint8\n",
        "        converter.inference_output_type = tf.uint8\n",
        "        converter.representative_dataset = rep_dataset_gen\n",
        "\n",
        "        # Convert\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        # Save calibrated TFLite\n",
        "        tflite_path = os.path.join(WORKSPACE, 'grove_ai_optimized_int8.tflite')\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "        print(f\"✅ Calibrated TFLite saved: {tflite_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Calibration failed: {e}\")\n",
        "        print(\"   Falling back to basic export...\")\n",
        "\n",
        "        # Fallback to basic export\n",
        "        tflite_path = model_export.export(\n",
        "            format='tflite',\n",
        "            imgsz=192,\n",
        "            int8=True,\n",
        "            optimize=True,\n",
        "            simplify=True\n",
        "        )\n",
        "\n"
      ],
      "metadata": {
        "id": "SvtyYyXRn2-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62470fcb-daf2-4a7d-ccca-7ffc1933efae"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Exporting với representative dataset calibration...\n",
            "   Step 1: Exporting to SavedModel...\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights/best.pt' with input shape (1, 3, 192, 192) BCHW and output shape(s) (1, 5, 756) (5.9 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.58...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.7s, saved as '/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights/best.onnx' (11.5 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.0...\n",
            "Saved artifact at '/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights/best_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 192, 192, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 5, 756), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  137615663607504: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  137615663600016: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
            "  137615663597904: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  137615663602320: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  137615743025232: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  137615663604240: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  137615663596944: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  137615663603664: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  137615663606928: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663611728: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663604432: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  137615663600784: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  137615663596176: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  137615663609616: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  137615663596368: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663604624: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663599440: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
            "  137615663602704: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  137615663610384: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  137615663611344: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  137615663607120: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615663603472: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615663601360: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615663603280: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663596560: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663606544: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  137615663601168: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  137615663605968: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  137615663600208: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  137615663609808: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  137615663598672: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  137615663603856: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  137615663604048: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  137615663598096: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663602128: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663597520: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  137615663607888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615663610768: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  137615663599248: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
            "  137615663609424: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615663604816: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  137615663595984: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615663607312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663598288: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663605776: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615663597136: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615663610576: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615663605008: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615663598864: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615663608464: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615663595792: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615663605584: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615663609232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663606736: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615663608080: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  137615663602896: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615646431888: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  137615663597328: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  137615646437456: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  137615646429776: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  137615646438416: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  137615646439184: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646434000: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646429200: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  137615646429392: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615646428048: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  137615646437072: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615646432080: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646438800: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646438992: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  137615646436496: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  137615646435152: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  137615646427856: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615646434384: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  137615646425168: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  137615646439376: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  137615646427472: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615646434576: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646437264: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646433232: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615646433808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615646427664: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615646440720: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615646432272: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646428240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646428816: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  137615646432848: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615646436688: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
            "  137615646440912: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615646435536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646428432: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646431312: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  137615646429584: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  137615646439760: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  137615646436304: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  137615646433040: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646432464: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615646437648: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  137615646430736: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615646435344: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  137615646431504: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615646425360: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615733160272: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  137615733158160: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615733153744: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615733151632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615627604176: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615627611856: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615733152016: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615733153360: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615733154512: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615733154320: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615733157392: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  137615733152976: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615733159120: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  137615733159312: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  137615733159504: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615627609360: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  137615627610896: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  137615627608976: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615627600720: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615627613008: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  137615627614736: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615627605904: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  137615627603216: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  137615627613200: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615627602064: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  137615627612816: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  137615627614352: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  137615627611664: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  137615627600144: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  137615627601680: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  137615627601104: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  137615733153168: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615646437840: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615627602640: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615627616080: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615627613392: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615627615696: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615733161808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615646427088: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615627606096: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615627607440: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615627615312: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615627612624: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615733157968: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615733159696: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615627609552: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615627599952: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615627614544: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615627607632: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615733154128: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615733158352: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615627613584: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n",
            "  137615627608400: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615627600336: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n",
            "  137615627603024: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615733158544: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n",
            "  137615733146640: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  137615627613968: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615627612240: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n",
            "  137615627615888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615627610512: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n",
            "  137615733157584: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  137615733153552: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n",
            "  137615627610320: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  137615627615504: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  137615627606480: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  137615627601296: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  137615627607824: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  137615627611280: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  137615627605328: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  137615627615120: TensorSpec(shape=(1, 2, 756), dtype=tf.float32, name=None)\n",
            "  137615627605712: TensorSpec(shape=(1, 2, 756), dtype=tf.float32, name=None)\n",
            "  137615627603408: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  137615627612432: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ✅ 19.8s, saved as '/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights/best_saved_model' (29.1 MB)\n",
            "\n",
            "Export complete (20.2s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights/best_saved_model imgsz=192  \n",
            "Validate:        yolo val task=detect model=/content/drive/MyDrive/grove_ai_qat_training_2/qat_grove_ai_optimized/weights/best_saved_model imgsz=192 data=/content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "   Step 2: Converting to TFLite với calibration...\n",
            "✅ Calibrated TFLite saved: /content/drive/MyDrive/grove_ai_qat_training_2/grove_ai_optimized_int8.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify exported model\n",
        "if os.path.exists(tflite_path):\n",
        "    tflite_size = os.path.getsize(tflite_path) / (1024**2)\n",
        "    print(f\"📦 TFLite Model Information:\")\n",
        "    print(f\"   File: {os.path.basename(tflite_path)}\")\n",
        "    print(f\"   Size: {tflite_size:.2f}MB\")\n",
        "    print(f\"   Target: Grove AI Vision (ARM Cortex-M55 + Ethos-U55)\")\n",
        "    print(f\"   Input: 192x192x3 (INT8)\")\n",
        "\n",
        "    # Copy to final location\n",
        "    final_tflite = os.path.join(WORKSPACE, 'grove_ai_final_deployment.tflite')\n",
        "    shutil.copy2(tflite_path, final_tflite)\n",
        "    print(f\"✅ Final deployment model: {final_tflite}\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"TFLite export failed\")"
      ],
      "metadata": {
        "id": "FClkL4zen9S_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba44b02-183a-458f-cc39-8248d6c98106"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 TFLite Model Information:\n",
            "   File: grove_ai_optimized_int8.tflite\n",
            "   Size: 3.11MB\n",
            "   Target: Grove AI Vision (ARM Cortex-M55 + Ethos-U55)\n",
            "   Input: 192x192x3 (INT8)\n",
            "✅ Final deployment model: /content/drive/MyDrive/grove_ai_qat_training_2/grove_ai_final_deployment.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "X5P3Iq-4iWKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f07ee00-ae3b-4a5b-ed99-6a8ab18ecb07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 COMPREHENSIVE PIPELINE VALIDATION\n",
            "============================================================\n",
            "\n",
            "🔍 Validating Stage 2 (192)...\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.2 ms, read: 27.7±6.0 MB/s, size: 48.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/valid/labels.cache... 479 images, 0 backgrounds, 0 corrupt: 100%|██████████| 479/479 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.864      0.794      0.873      0.521\n",
            "Speed: 0.1ms preprocess, 2.8ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n",
            "   mAP@0.5: 0.8727\n",
            "\n",
            "🔍 Validating QAT (192)...\n",
            "Ultralytics 8.3.159 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.2 ms, read: 26.3±8.9 MB/s, size: 47.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/grove_ai_qat_training_2/head_detection_on_bus-5/valid/labels.cache... 479 images, 0 backgrounds, 0 corrupt: 100%|██████████| 479/479 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:04<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        479        889      0.884      0.794      0.879      0.538\n",
            "Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val4\u001b[0m\n",
            "   mAP@0.5: 0.8787\n",
            "\n",
            "⚡ TESTING TFLITE INFERENCE SPEED\n",
            "   ⚡ CPU Inference: 15.93ms (62.8 FPS)\n",
            "\n",
            "🎯 GROVE AI VISION DEPLOYMENT SUMMARY\n",
            "============================================================\n",
            "Model                mAP@0.5    mAP@0.5:0.95\n",
            "---------------------------------------------\n",
            "Stage 2 (192)        0.8727     0.5213      \n",
            "QAT (192)            0.8787     0.5379      \n",
            "\n",
            "📦 FINAL DEPLOYMENT MODEL:\n",
            "   📁 File: /content/drive/MyDrive/grove_ai_qat_training_2/grove_ai_final_deployment.tflite\n",
            "   📏 Size: 3.11MB\n",
            "   🎯 Input: 192x192x3 (INT8)\n",
            "   🚀 Optimized: QAT + Representative Dataset Calibration\n",
            "   🤖 Target: ARM Cortex-M55 + Ethos-U55 NPU\n",
            "   ✅ QAT Performance: EXCELLENT (100.7% retention)\n",
            "\n",
            "🎉 PIPELINE COMPLETED SUCCESSFULLY!\n",
            "🚀 Grove AI Vision deployment model ready!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n📊 COMPREHENSIVE PIPELINE VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Performance comparison\n",
        "models_info = {\n",
        "    # 'Stage 1 (640→192)': (YOLO(stage1_model_path), 192),\n",
        "    'Stage 2 (192)': (YOLO(stage2_model_path), 192),\n",
        "    'QAT (192)': (YOLO(qat_model_path), 192)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, (model, imgsz) in models_info.items():\n",
        "    print(f\"\\n🔍 Validating {name}...\")\n",
        "    val_result = model.val(data=DATA_YAML_PATH, imgsz=imgsz, verbose=False)\n",
        "\n",
        "    results[name] = {\n",
        "        'map50': val_result.box.map50,\n",
        "        'map50_95': val_result.box.map,\n",
        "        'precision': val_result.box.mp,\n",
        "        'recall': val_result.box.mr\n",
        "    }\n",
        "\n",
        "    print(f\"   mAP@0.5: {val_result.box.map50:.4f}\")\n",
        "\n",
        "# TFLite inference speed test\n",
        "print(f\"\\n⚡ TESTING TFLITE INFERENCE SPEED\")\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    dummy_input = np.random.randint(0, 255, input_details[0]['shape'], dtype=input_details[0]['dtype'])\n",
        "\n",
        "    # Warmup\n",
        "    for _ in range(10):\n",
        "        interpreter.set_tensor(input_details[0]['index'], dummy_input)\n",
        "        interpreter.invoke()\n",
        "\n",
        "    # Measure speed\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        interpreter.set_tensor(input_details[0]['index'], dummy_input)\n",
        "        interpreter.invoke()\n",
        "    end_time = time.time()\n",
        "\n",
        "    avg_time_ms = (end_time - start_time) / 100 * 1000\n",
        "    est_fps = 1000 / avg_time_ms\n",
        "\n",
        "    print(f\"   ⚡ CPU Inference: {avg_time_ms:.2f}ms ({est_fps:.1f} FPS)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"   ❌ TFLite speed test failed: {e}\")\n",
        "\n",
        "# Final summary\n",
        "print(f\"\\n🎯 GROVE AI VISION DEPLOYMENT SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Model':<20} {'mAP@0.5':<10} {'mAP@0.5:0.95':<12}\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name:<20} {metrics['map50']:<10.4f} {metrics['map50_95']:<12.4f}\")\n",
        "\n",
        "print(f\"\\n📦 FINAL DEPLOYMENT MODEL:\")\n",
        "print(f\"   📁 File: {final_tflite}\")\n",
        "print(f\"   📏 Size: {tflite_size:.2f}MB\")\n",
        "print(f\"   🎯 Input: 192x192x3 (INT8)\")\n",
        "print(f\"   🚀 Optimized: QAT + Representative Dataset Calibration\")\n",
        "print(f\"   🤖 Target: ARM Cortex-M55 + Ethos-U55 NPU\")\n",
        "\n",
        "# Performance assessment\n",
        "qat_map50 = results['QAT (192)']['map50']\n",
        "stage2_map50 = results['Stage 2 (192)']['map50']\n",
        "retention = (qat_map50 / stage2_map50 * 100) if stage2_map50 > 0 else 0\n",
        "\n",
        "if retention >= 95:\n",
        "    print(f\"   ✅ QAT Performance: EXCELLENT ({retention:.1f}% retention)\")\n",
        "elif retention >= 90:\n",
        "    print(f\"   ✅ QAT Performance: GOOD ({retention:.1f}% retention)\")\n",
        "elif retention >= 85:\n",
        "    print(f\"   ⚠️  QAT Performance: ACCEPTABLE ({retention:.1f}% retention)\")\n",
        "else:\n",
        "    print(f\"   ❌ QAT Performance: NEEDS IMPROVEMENT ({retention:.1f}% retention)\")\n",
        "\n",
        "print(f\"\\n🎉 PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(f\"🚀 Grove AI Vision deployment model ready!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}